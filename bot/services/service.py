import logging
import asyncio
import sys
import subprocess
import io
import contextlib
import tempfile
import shutil
import glob
import traceback
import re
import os
import json
import base64
import hashlib
from urllib.parse import quote
import aiohttp
import aiofiles
from PIL import Image
import datetime
import html # Added for HTML escaping
from bs4 import BeautifulSoup
from aiogram.types import Message, CallbackQuery, FSInputFile, BufferedInputFile, InlineKeyboardButton
from aiogram.exceptions import TelegramBadRequest
from aiogram.utils.keyboard import InlineKeyboardBuilder
import markdown
from markdown_it import MarkdownIt
from pathlib import Path
import aiodocker
from aiodocker.exceptions import DockerError
import stat

from . import database
import matplobblib
from . import keyboards as kb
from . import github_service
from .config import *


logger = logging.getLogger(__name__)

RUNNER_IMAGE_NAME = "mpb-runner"
EXECUTION_TIMEOUT = 15
SHARED_DIR_INSIDE_BOT = "/app/code"
SHARED_VOLUME_NAME = "code_runner_data"

# --- HTML Conversion ---
def convert_html_to_telegram_html(html_content: str) -> str:
    """Converts generic HTML to Telegram-supported HTML."""
    # This is a simplified converter. For complex HTML, a library like `beautifulsoup4` would be better.
    # The order of replacements is important.
    
    # Pre-formatted text (code blocks)
    html_content = html_content.replace('<pre><code>', '<pre>').replace('</code></pre>', '</pre>')

    # Headers to bold
    for i in range(1, 7):
        html_content = html_content.replace(f'<h{i}>', '<b>').replace(f'</h{i}>', '</b>\n')

    # Paragraphs to newlines
    html_content = html_content.replace('<p>', '').replace('</p>', '\n')

    # Lists
    html_content = html_content.replace('<ul>', '').replace('</ul>', '')
    html_content = html_content.replace('<ol>', '').replace('</ol>', '')
    html_content = html_content.replace('<li>', '‚Ä¢ ').replace('</li>', '\n')

    # Bold and Italic
    html_content = html_content.replace('<em>', '<i>').replace('</em>', '</i>')
    html_content = html_content.replace('<strong>', '<b>').replace('</strong>', '</b>')
    
    # Horizontal rule
    html_content = html_content.replace('<hr>', '---').replace('<hr />', '---')

    # Blockquotes are not directly supported, just remove tags
    html_content = html_content.replace('<blockquote>', '').replace('</blockquote>', '\n')

    # Basic table conversion
    html_content = html_content.replace('<table>', '').replace('</table>', '')
    html_content = html_content.replace('<thead>', '').replace('</thead>', '')
    html_content = html_content.replace('<tbody>', '').replace('</tbody>', '')
    html_content = html_content.replace('<tr>', '').replace('</tr>', '\n')
    html_content = html_content.replace('<th>', '<b>').replace('</th>', '</b> | ')
    html_content = html_content.replace('<td>', '').replace('</td>', ' | ')

    # Clean up extra newlines and spaces
    lines = [line.strip() for line in html_content.split('\n')]
    return '\n'.join(filter(None, lines))


# --- LaTeX Rendering ---
def _render_latex_sync(latex_string: str, padding: int, dpi: int, is_display_override: bool | None = None) -> io.BytesIO:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ LaTeX –≤ PNG —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º latex –∏ dvipng, —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –æ—Ç—Å—Ç—É–ø–æ–≤."""

    # –î–ª—è –∫–æ–º–∞–Ω–¥—ã /latex –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º —Ñ–æ—Ä–º—É–ª—É –±–ª–æ—á–Ω–æ–π (display) –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.
    # –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ markdown —Ñ–ª–∞–≥ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è —è–≤–Ω–æ.
    is_display = is_display_override if is_display_override is not None else True

    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ—Å—Ç–æ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º
    processed_latex = latex_string.strip()

    # Heuristic fix for a common user error: placing \tag after the environment.
    # This moves the tag inside, right before the \end{...} command.
    processed_latex = re.sub(
        r'(\\end\{([a-zA-Z\*]+)\})(\s*\\tag\{.*?\})',
        r'\3 \1',
        processed_latex,
        flags=re.DOTALL
    )

    # Heuristic fix for primitive TeX commands like \atop used after an environment.
    processed_latex = re.sub(
        r'(\\end\{([a-zA-Z\*]+)\})(\s*\\atop\s*(\\text\{.*?\}))',
        r'\\ \4 \1',
        processed_latex,
        flags=re.DOTALL
    )
    
    # --- 
    # NOTE: pmatrix->array conversion is handled by pandoc_math_filter.lua
    # (we skip the Python-level regex to avoid double-conversion that corrupts math).

    # Heuristic fix for pmatrix environments containing \hline.
    # The pmatrix environment does not support \hline, causing a compilation error.
    # This fix replaces the pmatrix with a functionally equivalent array environment
    # which does support \hline.
    # processed_latex = re.sub(
    #     r'\\begin{pmatrix}(.*?)\\end{pmatrix}', 
    #     _pmatrix_hline_fixer, 
    #     processed_latex, 
    #     flags=re.DOTALL
    # )
    # --- 

    # –ë–æ–ª–µ–µ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫.
    if not re.search(r'\\begin\{[a-zA-Z\*]+\}.*?\\end\{[a-zA-Z\*]+\}', processed_latex, re.DOTALL):
        processed_latex = processed_latex.replace('\n', ' ')
    else:
        pass

    s = processed_latex

    # –°–ø–∏—Å–æ–∫ –æ–∫—Ä—É–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ —Å–∞–º–∏ —Å–æ–∑–¥–∞—é—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º.
    standalone_math_envs = [
        'equation', 'equation*', 'align', 'align*', 'gather', 'gather*',
        'multline', 'multline*', 'displaymath', 'math', 'alignat', 'alignat*',
        'flalign', 'flalign*', 'gathered' # Added gathered to the list
    ]
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å \begin{...}
    starts_with_standalone_env = False
    match = re.match(r'\\begin\{([a-zA-Z\*]+)\}', s.strip())
    if match and match.group(1) in standalone_math_envs:
        starts_with_standalone_env = True

    is_already_math_env = (
        (s.startswith('$') and s.endswith('$')) or
        (s.startswith('$$') and s.endswith('$$')) or
        (s.startswith(r'\[') and s.endswith(r'\]')) or
        starts_with_standalone_env
    )
    
    contains_tag = r'\tag' in s
    
    # The \tag command is only for display math, so we force display mode.
    if contains_tag:
        is_display = True

    # Only wrap the expression if it isn't already in a math environment
    if not is_already_math_env:
        if contains_tag:
            processed_latex = f'\\begin{{equation*}}\n{processed_latex}\n\\end{{equation*}}'
        else:
            if is_display:
                processed_latex = f'\\[{processed_latex}\\]'
            else:
                processed_latex = f'${processed_latex}$'
                
    full_latex_code = LATEX_PREAMBLE + processed_latex + LATEX_POSTAMBLE

    with tempfile.TemporaryDirectory() as temp_dir:
        tex_path = os.path.join(temp_dir, 'formula.tex')
        log_path = os.path.join(temp_dir, 'formula.log')
        dvi_path = os.path.join(temp_dir, 'formula.dvi')
        png_path = os.path.join(temp_dir, 'formula.png')

        with open(tex_path, 'w', encoding='utf-8') as f:
            f.write(full_latex_code)

        # --- –ó–∞–ø—É—Å–∫ LaTeX ---
        process = subprocess.run(
            ['latex', '-interaction=nonstopmode', '-output-directory', temp_dir, tex_path],
            capture_output=True, text=True, encoding='utf-8', errors='ignore'
        )

        # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫–∏ LaTeX ---
        if not os.path.exists(dvi_path) or process.returncode != 0:
            error_message = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ LaTeX."
            if os.path.exists(log_path):
                with open(log_path, 'r', encoding='utf-8', errors='ignore') as log_file:
                    log_content = log_file.read()
                    error_lines = [line for line in log_content.split('\n') if line.startswith('! ')]
                    if error_lines:
                        error_message = error_lines[0].strip()
                    else:
                       error_message = "...\n" + "\n".join(log_content.split('\n')[-20:])
                       raise ValueError(f"–û—à–∏–±–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ LaTeX:\n{error_message}")

        # --- –ó–∞–ø—É—Å–∫ dvipng –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ DVI –≤ PNG ---
        dvipng_process = subprocess.run(
            ['dvipng', '-D', str(dpi), '-T', 'tight', '-bg', 'Transparent', '-o', png_path, dvi_path],
            capture_output=True, text=True, encoding='utf-8', errors='ignore'
        )
        
        if dvipng_process.returncode != 0 or not os.path.exists(png_path):
            raise RuntimeError(f"–û—à–∏–±–∫–∞ dvipng: {dvipng_process.stderr}")

        # --- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Ç—Å—Ç—É–ø–æ–≤ –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Pillow ---
        with Image.open(png_path) as img:
            if is_display:
                target_width = 600
                final_width = max(img.width + 2 * padding, target_width)
                final_height = img.height + 2 * padding
                new_img = Image.new("RGBA", (final_width, final_height), (0, 0, 0, 0))
                paste_x = (final_width - img.width) // 2
                paste_y = padding
                new_img.paste(img, (paste_x, paste_y))
            else:
                final_width = img.width + 2 * padding
                final_height = img.height + 2 * padding
                new_img = Image.new("RGBA", (final_width, final_height), (0, 0, 0, 0))
                new_img.paste(img, (padding, padding))

            buf = io.BytesIO()
            new_img.save(buf, format='PNG')
            buf.seek(0)
            return buf
                    
async def render_latex_to_image(latex_string: str, padding: int, dpi:int = 300, is_display_override: bool | None = None) -> io.BytesIO:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ LaTeX, –≤—ã–ø–æ–ª–Ω—è–µ–º–∞—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ."""
    return await asyncio.to_thread(_render_latex_sync, latex_string, padding, dpi, is_display_override)

# --- Mermaid Rendering ---
def _render_mermaid_sync(mermaid_code: str) -> io.BytesIO:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ Mermaid –≤ PNG —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º mmdc."""
    with tempfile.TemporaryDirectory() as temp_dir:
        input_path = os.path.join(temp_dir, 'diagram.mmd')
        output_path = os.path.join(temp_dir, 'diagram.png')

        with open(input_path, 'w', encoding='utf-8') as f:
            f.write(mermaid_code)

        # Dynamically find the mmdc executable path
        mmdc_path = shutil.which('mmdc')
        if not mmdc_path:
            raise FileNotFoundError("Mermaid CLI (mmdc) not found in PATH. Please ensure it is installed correctly in the Docker image.")

        # –ó–∞–ø—É—Å–∫ Mermaid CLI (mmdc)
        process = subprocess.run(
            [
                mmdc_path, '-p', str(PUPPETEER_CONFIG_PATH),
                '-i', input_path, '-o', output_path, '-b', 'transparent'
            ],
            capture_output=True, text=True, encoding='utf-8', errors='ignore'
        )

        if process.returncode != 0 or not os.path.exists(output_path):
            error_output = process.stderr or process.stdout or "Unknown error."
            # –û—á–∏—â–∞–µ–º –≤—ã–≤–æ–¥ –æ—Ç –ª–∏—à–Ω–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ Puppeteer
            clean_error = re.sub(r'\(node:\d+\) \[[^\]]+\] ', '', error_output)
            raise ValueError(f"–û—à–∏–±–∫–∞ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ Mermaid:\n{clean_error.strip()}")

        # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –±—É—Ñ–µ—Ä
        with open(output_path, 'rb') as f:
            buf = io.BytesIO(f.read())
        
        buf.seek(0)
        return buf

async def render_mermaid_to_image(mermaid_code: str) -> io.BytesIO:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ Mermaid, –≤—ã–ø–æ–ª–Ω—è–µ–º–∞—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ."""
    return await asyncio.to_thread(_render_mermaid_sync, mermaid_code)

def _pmatrix_hline_fixer(match: re.Match) -> str:
    """Callback-—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è \hline –≤–Ω—É—Ç—Ä–∏ pmatrix."""
    matrix_content = match.group(1)
    if r'\hline' in matrix_content:
        lines = matrix_content.strip().split(r'\\')
        num_cols = 0
        for line in lines:
            if r'\hline' in line.strip(): continue
            clean_line = re.sub(r'\\text\{.*?\}', '', line)
            current_cols = clean_line.count('&') + 1
            if current_cols > num_cols:
                num_cols = current_cols
        if num_cols == 0 and len(lines) > 0: num_cols = 1
        if num_cols > 0:
            col_spec = 'c' * num_cols
            return f'\\left(\\begin{{array}}{{{col_spec}}}{matrix_content}\\end{{array}}\\right)'
    return match.group(0)

# service.py

# ... (–∏–º–ø–æ—Ä—Ç—ã –∏ –¥—Ä—É–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏, –≤–∫–ª—é—á–∞—è _pmatrix_hline_fixer) ...

def _convert_md_to_pdf_pandoc_sync(markdown_string: str, title: str, contributors: list | None = None, last_modified_date: str | None = None) -> io.BytesIO:
    """
    –§–∏–Ω–∞–ª—å–Ω–∞—è, –Ω–∞–¥–µ–∂–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ Markdown –≤ PDF.
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è "–ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–π –∑–∞—â–∏—Ç—ã":
    1. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ Markdown –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç—ã—Ö –æ—à–∏–±–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è .tex —Ñ–∞–π–ª–∞ —Å –ø–æ–º–æ—â—å—é Pandoc.
    3. –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ .tex —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ Pandoc.
    4. –ö–æ–º–ø–∏–ª—è—Ü–∏—è –≤ PDF.
    """
    # --- –≠–¢–ê–ü 1: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ Markdown –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---

    # 1. –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ \tag{...} –≤–Ω—É—Ç—Ä—å –æ–∫—Ä—É–∂–µ–Ω–∏–π.
    markdown_string = re.sub(
        r'(\\end\{([a-zA-Z\*]+)\})(\s*\\tag\{.*?\})',
        r'\3 \1',
        markdown_string,
        flags=re.DOTALL
    )

    # 2. –ù–û–í–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–µ–π –∫–æ–º–∞–Ω–¥—ã \atop –ø–æ—Å–ª–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
    # –ú—ã –∑–∞–º–µ–Ω—è–µ–º –µ–µ –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É (\\) –∏ –ø–µ—Ä–µ–º–µ—â–∞–µ–º —Ç–µ–∫—Å—Ç –≤–Ω—É—Ç—Ä—å –æ–∫—Ä—É–∂–µ–Ω–∏—è.
    markdown_string = re.sub(
        r'(\\end\{([a-zA-Z\*]+)\})(\s*\\atop\s*(\\text\{.*?\}))',
        r'\\ \4 \1', # --> \\ \text{...} \end{align}
        markdown_string,
        flags=re.DOTALL
    )

    # 3. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è align* –≤ align, –µ—Å–ª–∏ –≤–Ω—É—Ç—Ä–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è \tag.
    def fix_starred_env_with_tag(match):
        env_name = match.group(1)
        content = match.group(2)
        if r'\tag' in content:
            return f"\\begin{{{env_name}}}{content}\\end{{{env_name}}}"
        return match.group(0)

    markdown_string = re.sub(
        r'\\begin\{([a-zA-Z]+)\*\}(.*?)\\end\{\1\*\}',
        fix_starred_env_with_tag,
        markdown_string,
        flags=re.DOTALL
    )

    # 4. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ \hline –≤–Ω—É—Ç—Ä–∏ pmatrix.
    markdown_string = re.sub(
        r'\\begin{pmatrix}(.*?)\\end{pmatrix}',
        _pmatrix_hline_fixer,
        markdown_string,
        flags=re.DOTALL
    )

    if contributors:
        author_links = [r"\href{" + f"{c['html_url']}" + r"}{" + f"{c['login']}" + r"}" for c in contributors]
        author_string = ", ".join(author_links)
    else:
        author_string = "Matplobbot"

    date_string = last_modified_date or datetime.datetime.now().strftime("%d %B %Y")

    with tempfile.TemporaryDirectory() as temp_dir:
        header_path = os.path.join(temp_dir, 'header.tex')
        with open(header_path, 'w', encoding='utf-8') as f:
            f.write(PANDOC_HEADER_INCLUDES)

        try:
            base_name = 'document'
            tex_path = os.path.join(temp_dir, f'{base_name}.tex')
            pdf_path = os.path.join(temp_dir, f'{base_name}.pdf')

            # --- –≠–¢–ê–ü 2: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Markdown –≤ .tex —Å –ø–æ–º–æ—â—å—é Pandoc ---
            pandoc_to_tex_command = [
                'pandoc',
                '--filter', str(MERMAID_FILTER_PATH),
                '--lua-filter', str(MATH_FILTER_PATH),
                '--from=gfm-yaml_metadata_block+tex_math_dollars+raw_tex',
                '--to=latex',
                '--pdf-engine=xelatex', '--include-in-header', header_path,
                '--variable', f'title={title}',
                '--variable', f'author={author_string}',
                '--variable', f'date={date_string}',
                '--variable', 'documentclass=article',
                '--variable', 'geometry:margin=2cm',
                '-o', tex_path
            ]
            if re.search(r'^# ', markdown_string, re.MULTILINE):
                pandoc_to_tex_command.append('--toc')

            pandoc_process = subprocess.run(
                pandoc_to_tex_command, input=markdown_string.encode('utf-8'), capture_output=True
            )
            if pandoc_process.returncode != 0:
                raise RuntimeError(f"–û—à–∏–±–∫–∞ Pandoc –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ .tex: {pandoc_process.stderr.decode('utf-8', 'ignore')}")

            # --- –≠–¢–ê–ü 3: –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ .tex —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ Pandoc ---
            if not os.path.exists(tex_path):
                raise RuntimeError(f"Pandoc –Ω–µ —Å–º–æ–≥ —Å–æ–∑–¥–∞—Ç—å .tex —Ñ–∞–π–ª. Stderr: {pandoc_process.stderr.decode('utf-8', 'ignore')}")

            with open(tex_path, 'r', encoding='utf-8') as f:
                tex_content = f.read()
            
            # –£–±–∏—Ä–∞–µ–º –æ—à–∏–±–æ—á–Ω—É—é –æ–±–µ—Ä—Ç–∫—É \[ ... \] –≤–æ–∫—Ä—É–≥ –æ–∫—Ä—É–∂–µ–Ω–∏–π amsmath
            math_envs = r'(?:align|gather|equation|multline)'
            pattern = re.compile(
                r'\\\[\s*(\\begin\{' + math_envs + r'\*?\}.*?\\end\{' + math_envs + r'\*?\})\s*\\\]',
                re.DOTALL
            )
            tex_content_fixed = pattern.sub(r'\1', tex_content)

            with open(tex_path, 'w', encoding='utf-8') as f:
                f.write(tex_content_fixed)

            # --- –≠–¢–ê–ü 4: –ö–æ–º–ø–∏–ª—è—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ .tex –≤ PDF ---
            compile_command = [
                'latexmk',
                '-file-line-error',
                '-pdf',
                '-xelatex',
                '-interaction=nonstopmode',
                f'-output-directory={temp_dir}',
                tex_path
            ]
            compile_process = subprocess.run(compile_command, capture_output=True, text=True, encoding='utf-8', errors='ignore')

            if not os.path.exists(pdf_path) or compile_process.returncode != 0:
                log_content = "Log file not found."
                log_path = os.path.join(temp_dir, f'{base_name}.log')
                if os.path.exists(log_path):
                    with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
                        log_content = f.read()

                fatal_error_match = re.search(r"^!.*$", log_content, re.MULTILINE)
                if fatal_error_match:
                    error_start_index = fatal_error_match.start()
                    context_end_index = log_content.find('\n\n', error_start_index)
                    if context_end_index == -1: context_end_index = error_start_index + 500
                    error_message = log_content[error_start_index:context_end_index].strip()
                else:
                    error_message = "–§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ .log, –Ω–æ –∫–æ–º–ø–∏–ª—è—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å. –ö–æ–Ω–µ—Ü –ª–æ–≥–∞:\n" + log_content[-2000:]
                
                process_output = (compile_process.stdout or "No stdout.") + "\n" + (compile_process.stderr or "No stderr.")
                error_header = "PDF-—Ñ–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω." if not os.path.exists(pdf_path) else "–ö–æ–º–ø–∏–ª—è—Ü–∏—è PDF –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ."
                
                raise RuntimeError(
                    f"–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {error_header}\n\n"
                    f"--- –ö–õ–Æ–ß–ï–í–ê–Ø –û–®–ò–ë–ö–ê –ò–ó –õ–û–ì–ê ---\n{error_message}\n\n"
                    f"--- –í–´–í–û–î LATEXMK (stdout/stderr) ---\n{process_output[-2000:]}"
                )

            with open(pdf_path, 'rb') as f:
                return io.BytesIO(f.read())
        finally:
            # –≠—Ç–∞ –ª–æ–≥–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è –≤—Å–µ–≥–¥–∞, –¥–∞–∂–µ –µ—Å–ª–∏ –≤ try –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç –æ—à–∏–±–∫–∞.
            cleanup_log_file = '/tmp/pandoc_cleanup.log'
            if os.path.exists(cleanup_log_file):
                try:
                    with open(cleanup_log_file, 'r', encoding='utf-8') as f:
                        files_to_delete = f.readlines()
                    
                    for file_path in files_to_delete:
                        path = file_path.strip()
                        if path:  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è
                            try:
                                os.remove(path)
                                logger.debug(f"–£—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª Mermaid: {path}")
                            except FileNotFoundError:
                                # –§–∞–π–ª —É–∂–µ —É–¥–∞–ª–µ–Ω, —ç—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞
                                logger.warning(f"–í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª Mermaid –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è: {path}")
                            except Exception as e:
                                # –õ–æ–≥–∏—Ä—É–µ–º –¥—Ä—É–≥–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏
                                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {path}: {e}")
                    
                    # –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É–¥–∞–ª—è–µ–º —Å–∞–º —Ñ–∞–π–ª –ª–æ–≥–∞, —á—Ç–æ–±—ã –æ–Ω –Ω–µ —Ä–æ—Å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ
                    os.remove(cleanup_log_file)
                except Exception as e:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–ª–∏ —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª –ª–æ–≥–∞ –æ—á–∏—Å—Ç–∫–∏ {cleanup_log_file}: {e}")

async def convert_md_to_pdf_pandoc(markdown_string: str, title: str, contributors: list | None = None, last_modified_date: str | None = None) -> io.BytesIO:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ Markdown –≤ PDF —Å –ø–æ–º–æ—â—å—é pandoc."""
    return await asyncio.to_thread(_convert_md_to_pdf_pandoc_sync, markdown_string, title, contributors, last_modified_date)

async def _resolve_wikilinks(content: str, repo_path: str, all_repo_files: list[str], target_format: str = 'md') -> str:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ [[wikilinks]] –∏ –∑–∞–º–µ–Ω—è–µ—Ç –∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ Markdown-—Å—Å—ã–ª–∫–∞–º–∏.
    –≠—Ç–∞ –≤–µ—Ä—Å–∏—è –∏–∑–±–µ–≥–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Å—ã–ª–æ–∫ –≤–Ω—É—Ç—Ä–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ–∫—Ä—É–∂–µ–Ω–∏–π LaTeX.
    –û–Ω–∞ *–≤—Å–µ–≥–¥–∞* –≤—ã–≤–æ–¥–∏—Ç Markdown-—Å—Å—ã–ª–∫–∏, –ø–æ–∑–≤–æ–ª—è—è Pandoc –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å
    —Ñ–∏–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –≤ LaTeX –∏–ª–∏ HTML, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º.
    """
    if not all_repo_files or '[[' not in content:
        return content

    # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ –∏—Ö "–≤–∏–∫–∏-–∏–º–µ–Ω–∞–º"
    file_map = {os.path.splitext(os.path.basename(f))[0].lower(): f for f in all_repo_files}

    def replace_wikilink(match):
        inner_content = match.group(1).strip()
        parts = inner_content.split('|', 1)
        file_name_part = parts[0].strip()
        display_text = parts[1].strip() if len(parts) > 1 else file_name_part
        found_path = file_map.get(file_name_part.lower())

        if found_path:
            # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—É—é URL-—Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–∞–π–ª –≤ GitHub
            url = f"https://github.com/{repo_path}/blob/{github_service.MD_SEARCH_BRANCH}/{quote(found_path)}"
            
            # --- –í–°–ï–ì–î–ê –í–û–ó–í–†–ê–©–ê–ï–ú –°–¢–ê–ù–î–ê–†–¢–ù–£–Æ MARKDOWN-–°–°–´–õ–ö–£ ---
            # Pandoc —Å–∞–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç [—Ç–µ–∫—Å—Ç](url) –≤ \href{url}{—Ç–µ–∫—Å—Ç}
            # –∏ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ 'md' –∏ 'latex' –∑–¥–µ—Å—å –Ω–µ –Ω—É–∂–Ω–æ.
            return f"[{display_text}]({url})"
        else:
            # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç
            return f"_{display_text}_"

    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ [[wikilinks]]
    wikilink_regex = r"\[\[([^\]]+)\]\]"

    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –±–ª–æ–∫–æ–≤ LaTeX, —á—Ç–æ–±—ã –∏—Ö –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å
    math_env_regex = r'(\$\$.*?\$\$|\$[^$\n]*?\$|\\\[.*?\\\]|\\\(.*?\\\)|\\begin\{(?:equation|align|gather|math|displaymath|matrix|pmatrix|array)[\*]?\}.*?\\end\{(?:equation|align|gather|math|displaymath|matrix|pmatrix|array)[\*]?\})'
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞—Å—Ç–∏
    parts = re.split(math_env_regex, content, flags=re.DOTALL)

    processed_parts = []
    for i, part in enumerate(parts):
        # –ß–µ—Ç–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã - —ç—Ç–æ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç, –≤ –Ω–∏—Ö –∏—â–µ–º –∏ –∑–∞–º–µ–Ω—è–µ–º —Å—Å—ã–ª–∫–∏
        if i % 2 == 0:
            processed_parts.append(re.sub(wikilink_regex, replace_wikilink, part))
        # –ù–µ—á–µ—Ç–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã - —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞, –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Ö –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        else:
            processed_parts.append(part)

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
    return "".join(processed_parts)

async def send_as_plain_text(message: Message, file_path: str, content: str):
    """Helper to send content as plain text, handling long messages."""
    header = f"–§–∞–π–ª: `{file_path}` (–ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç)\n\n"
    
    await message.answer(header, parse_mode='markdown')
    # Send content in chunks
    if len(content) == 0:
        await message.answer("_(—Ñ–∞–π–ª –ø—É—Å—Ç)_", parse_mode='markdown')
        return

    for x in range(0, len(content), 4000): # Use a slightly smaller chunk size for safety with markdown ```
        chunk = content[x:x+4000]
        await message.answer(f"```\n{chunk}\n```", parse_mode='markdown')

async def send_as_document_from_url(message: Message, file_url: str, file_path: str):
    """Downloads a file from a URL by chunks and sends it as a document."""
    file_name = os.path.basename(file_path)
    status_msg = await message.answer(f"–ó–∞–≥—Ä—É–∂–∞—é —Ñ–∞–π–ª `{file_name}`...", parse_mode='markdown')
    
    temp_file_path = None
    try:
        # Create a temporary file to store the download
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{file_name}") as tmp_file:
            temp_file_path = tmp_file.name

        async with aiohttp.ClientSession() as session:
            async with session.get(file_url) as response:
                response.raise_for_status() # Raise an exception for bad status codes
                
                # Stream the download in chunks
                async with aiofiles.open(temp_file_path, 'wb') as f:
                    async for chunk in response.content.iter_chunked(8192):
                        await f.write(chunk)
        
        # Send the downloaded file
        await message.answer_document(
            document=FSInputFile(temp_file_path, filename=file_name),
            caption=f"–§–∞–π–ª: `{file_path}`",
            parse_mode='markdown'
        )
        await status_msg.delete()

    except Exception as e:
        logger.error(f"Failed to download/send file from {file_url}: {e}", exc_info=True)
        await status_msg.edit_text(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª `{file_name}`. –û—à–∏–±–∫–∞: {e}")
    finally:
        if temp_file_path and os.path.exists(temp_file_path):
            os.remove(temp_file_path)

async def display_github_file(message: Message, user_id: int, repo_path: str, file_path: str, status_msg_to_delete: Message | None = None):
    """
    Fetches a file from GitHub and displays it, using Telegra.ph for Markdown files."""
    # The initial "Processing..." message is now sent from the handler.
    raw_url = f"https://raw.githubusercontent.com/{repo_path}/{github_service.MD_SEARCH_BRANCH}/{file_path}"

    # Check if it's a markdown file
    if file_path.lower().endswith('.md'):
        # --- Existing logic for Markdown files ---
        # This part fetches content as text and processes it.
        content = github_service.github_content_cache.get(file_path)
        if content is not None:
            logger.info(f"Cache hit for file content: {file_path}")
        else:
            logger.info(f"Cache miss for file content: {file_path}. Fetching from GitHub.")
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(raw_url) as response:
                        if response.status == 200:
                            content = await response.text(encoding='utf-8', errors='ignore')
                            github_service.github_content_cache[file_path] = content # Store in cache
                        else:
                            await message.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª. –û—à–∏–±–∫–∞: {response.status}")
                            return
            except Exception as e:
                await message.answer(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
                return

        if content is None:
            await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞.")
            return

        # Get user settings to decide how to display the file
        settings = await database.get_user_settings(user_id)
        md_mode = settings.get('md_display_mode', 'md_file')
        
        await message.bot.send_chat_action(message.chat.id, "upload_document") 
        
        # Option 1: .md file
        if md_mode == 'md_file':
            file_name = file_path.split('/')[-1]
            file_bytes = content.encode('utf-8')
            await message.answer_document(
                document=BufferedInputFile(file_bytes, filename=file_name),
                caption=f"–§–∞–π–ª –∫–æ–Ω—Å–ø–µ–∫—Ç–∞: `{file_path}`",
                parse_mode='markdown'
            )

        # Option 2: .pdf file
        elif md_mode == 'pdf_file':
            try:
                page_title = file_path.split('/')[-1].replace('.md', '')
                file_name = f"{page_title}.pdf"

                async with aiohttp.ClientSession() as session:
                    # --- WIKILINK INTEGRATION ---
                    all_repo_files = await github_service.get_all_repo_files_cached(repo_path, session)
                    resolved_content = await _resolve_wikilinks(content, repo_path, all_repo_files, target_format='latex')
                    # --- END WIKILINK INTEGRATION ---
                    contributors = await github_service.get_repo_contributors(repo_path, session)
                    last_modified_date = await github_service.get_file_last_modified_date(repo_path, file_path, session)
                    pdf_buffer = await convert_md_to_pdf_pandoc(resolved_content, page_title, contributors, last_modified_date)

                await message.answer_document(document=BufferedInputFile(pdf_buffer.getvalue(), filename=file_name), caption=f"PDF-–≤–µ—Ä—Å–∏—è –∫–æ–Ω—Å–ø–µ–∫—Ç–∞: `{file_path}`", parse_mode='markdown')
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ PDF –¥–ª—è '{file_path}': {e}", exc_info=True)
                # --- NEW FIX: Truncate long error messages to avoid TelegramBadRequest ---
                error_message = str(e)
                max_len = 3900 # Even more safe to account for prefix text
                if len(error_message) > max_len:
                    truncated_error = error_message[:max_len] + "\n\n... (—Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –±—ã–ª–æ —Å–æ–∫—Ä–∞—â–µ–Ω–æ)"
                else:
                    truncated_error = error_message
                await message.answer(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ PDF-—Ñ–∞–π–ª–∞: {truncated_error}. –û—Ç–ø—Ä–∞–≤–ª—è—é –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")
                await send_as_plain_text(message, file_path, content) # Fallback
        # Option 3: .html file
        elif md_mode == 'html_file':
            try:
                page_title = file_path.split('/')[-1].replace('.md', '')
                # --- WIKILINK INTEGRATION ---
                async with aiohttp.ClientSession() as session:
                    all_repo_files = await github_service.get_all_repo_files_cached(repo_path, session)
                resolved_content = await _resolve_wikilinks(content, repo_path, all_repo_files, target_format='md')
                full_html_doc = await _prepare_html_with_katex(resolved_content, page_title)
                # --- END WIKILINK INTEGRATION ---

                file_bytes = full_html_doc.encode('utf-8')
                file_name = f"{page_title}.html"
                await message.answer_document(
                    document=BufferedInputFile(file_bytes, filename=file_name),
                    caption=f"HTML-–≤–µ—Ä—Å–∏—è –∫–æ–Ω—Å–ø–µ–∫—Ç–∞: `{file_path}`",
                    parse_mode='markdown'
                )
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ HTML-—Ñ–∞–π–ª–∞ —Å KaTeX –¥–ª—è '{file_path}': {e}", exc_info=True)
                await message.answer(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ HTML-—Ñ–∞–π–ª–∞: {e}. –û—Ç–ø—Ä–∞–≤–ª—è—é –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")
                await send_as_plain_text(message, file_path, content) # Fallback
        
        # Fallback for unknown mode
        else:
            logger.warning(f"Unknown md_display_mode '{md_mode}' for user {user_id}. Falling back to plain text.")
            await send_as_plain_text(message, file_path, content)
    else:
        # Not a markdown file, download and send as a document
        await send_as_document_from_url(message, raw_url, file_path)
    
    # Finally, delete the status message and show the main keyboard
    if status_msg_to_delete:
        try:
            await status_msg_to_delete.delete()
        except TelegramBadRequest:
            pass # Message might have been deleted already
    await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –∫–æ–º–∞–Ω–¥—É:", reply_markup=kb.get_main_reply_keyboard(user_id))

async def _prepare_html_with_katex(content: str, page_title: str) -> str:
    """
    Prepares a self-contained HTML document with a navigation panel, client-side rendering
    for LaTeX (using KaTeX), and Mermaid diagrams. This is the definitive, feature-complete version.
    """
    
    # --- Step 1: Isolate all valid math blocks with the robust regex ---
    latex_formulas = []
    def store_and_replace_latex(match):
        placeholder = f"<!--KATEX_PLACEHOLDER_{len(latex_formulas)}-->"
        latex_formulas.append(match.group(0))
        return placeholder

    latex_regex = r'(\$\$.*?\$\$|\$[^$\n]*?\$)'
    content_with_placeholders = re.sub(latex_regex, store_and_replace_latex, content, flags=re.DOTALL)

    # --- Step 2: Render the Markdown into an initial HTML string ---
    md = MarkdownIt("commonmark", {"html": True, "linkify": True, "typographer": True}).enable('table')
    html_content = md.render(content_with_placeholders)

    # --- Step 3: Generate Navigation Panel and Add IDs to Headers ---
    soup = BeautifulSoup(html_content, 'html.parser')
    headings = soup.find_all(['h1', 'h2', 'h3'])
    toc_items = []
    used_ids = set()

    for heading in headings:
        text = heading.get_text()
        # Create a URL-friendly "slug" for the ID
        # --- WIKILINK FIX: Use original heading text for TOC, not slugified version ---
        # The slug is only for the 'id' attribute. The visible text should be original.
        # This was already correct, just adding a comment for clarity.
        # slug_base = re.sub(r'[^\w\s-]', '', text.lower()).strip().replace(' ', '-')
        # ...
        # toc_items.append({'level': level, 'text': text, 'id': slug})

        slug_base = re.sub(r'[^\w\s-]', '', text.lower()).strip().replace(' ', '-')
        slug = slug_base
        counter = 1
        # Ensure the ID is unique
        while slug in used_ids:
            slug = f"{slug_base}-{counter}"
            counter += 1
        
        used_ids.add(slug)
        heading['id'] = slug
        
        level = int(heading.name[1]) # Gets the number from 'h1', 'h2', etc.
        toc_items.append({'level': level, 'text': text, 'id': slug})

    # Build the TOC HTML
    toc_html = '<nav class="toc"><h4>–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ</h4><ul>'
    for item in toc_items:
        toc_html += f'<li class="toc-level-{item["level"]}"><a href="#{item["id"]}">{item["text"]}</a></li>'
    toc_html += '</ul></nav>'

    # Get the HTML with the newly added IDs in the header tags
    html_content_with_ids = str(soup)

    # --- Step 4: Process and re-insert the stored math formulas ---
    processed_formulas = []
    for formula_string in latex_formulas:
        is_display = formula_string.startswith('$$')
        content_start, content_end = (2, -2) if is_display else (1, -1)
        original_content = formula_string[content_start:content_end].strip()

        if is_display and ('\n' in original_content or r'\atop' in original_content):
            temp_content = original_content.replace(r'\atop', r'\\')
            original_content = f"\\begin{{gathered}}\n{temp_content}\n\\end{{gathered}}"

        protected_blocks = []
        def protect_text_blocks(m):
            placeholder = f"__TEXT_BLOCK_{len(protected_blocks)}__"
            protected_blocks.append(m.group(0))
            return placeholder
        
        temp_content = re.sub(r'\\text\{.*?\}', protect_text_blocks, original_content, flags=re.DOTALL)
        temp_content = re.sub(r'([\u0400-\u04FF]+(?:[\s.,][\u0400-\u04FF]+)*)', r'\\text{\1}', temp_content)
        for i, block in enumerate(protected_blocks):
            temp_content = temp_content.replace(f"__TEXT_BLOCK_{i}__", block)
        
        final_content = html.escape(temp_content)

        if is_display:
            processed_formulas.append(f'$${final_content}$$')
        else:
            processed_formulas.append(f'${final_content}$')

    # Re-insert into the HTML that already has header IDs
    final_html_content = html_content_with_ids
    for i, formula in enumerate(processed_formulas):
        placeholder = f"<!--KATEX_PLACEHOLDER_{i}-->"
        final_html_content = final_html_content.replace(placeholder, formula)

    # --- Step 5: Final preparation and templating ---
    final_html_content = final_html_content.replace(
        '<pre><code class="language-mermaid">', '<pre class="mermaid">'
    ).replace('</code></pre>', '</pre>')

    full_html_doc = f"""
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{page_title}</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body, {{ delimiters: [ {{left: '$$', right: '$$', display: true}}, {{left: '$', right: '$', display: false}} ], throwOnError: false }});"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
        :root {{
            --bg-color: #ffffff; --text-color: #24292e; --link-color: #0366d6;
            --border-color: #eaecef; --code-bg-color: #f6f8fa;
        }}
        html {{ scroll-behavior: smooth; }} /* This enables smooth scrolling */
        body {{ 
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; 
            line-height: 1.6; margin: 0 auto; padding: 20px 20px 20px 300px; /* Add left padding for TOC */
            max-width: 800px; 
            background-color: var(--bg-color); color: var(--text-color);
        }}
        @media (prefers-color-scheme: dark) {{
            :root:not(.light-theme) {{
                --bg-color: #0d1117; --text-color: #c9d1d9; --link-color: #58a6ff;
                --border-color: #30363d; --code-bg-color: #161b22;
            }}
        }}

        /* ----- Navigation Panel (TOC) Styles ----- */
        .toc {{
            position: fixed;
            top: 20px;
            left: 20px;
            width: 240px;
            max-height: 90vh;
            overflow-y: auto;
            padding: 16px;
            background-color: var(--code-bg-color);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            font-size: 14px;
        }}
        .toc h4 {{
            margin-top: 0;
            margin-bottom: 10px;
            font-size: 16px;
            border-bottom: 1px solid var(--border-color);
            padding-bottom: 8px;
        }}
        .toc ul {{
            list-style-type: none;
            padding: 0;
            margin: 0;
        }}
        .toc li a {{
            text-decoration: none;
            color: var(--text-color);
            display: block;
            padding: 4px 0;
            border-radius: 4px;
        }}
        .toc li a:hover {{
            background-color: var(--border-color);
        }}
        .toc .toc-level-2 {{ margin-left: 15px; }}
        .toc .toc-level-3 {{ margin-left: 30px; }}

        /* Responsive: Hide TOC on smaller screens */
        @media (max-width: 1200px) {{
            .toc {{ display: none; }}
            body {{ padding: 20px; }} /* Reset body padding */
        }}

        /* ----- General Element Styling ----- */
        a {{ color: var(--link-color); }}
        pre {{ background-color: var(--code-bg-color); padding: 16px; overflow: auto; border-radius: 6px; position: relative; border: 1px solid var(--border-color); }}
        code {{ font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace; }}
        table {{ border-collapse: collapse; width: 100%; margin: 1em 0; border: 1px solid var(--border-color); }}
        th, td {{ border: 1px solid var(--border-color); padding: 6px 13px; text-align: left; }}
        tr:nth-child(2n) {{ background-color: var(--code-bg-color); }}
        h1, h2, h3, h4, h5, h6 {{ border-bottom: 1px solid var(--border-color); padding-bottom: .3em; margin-top: 24px; margin-bottom: 16px; }}
        .copy-btn {{
            position: absolute; top: 8px; right: 8px; padding: 4px 8px; font-size: 12px;
            background-color: #e1e4e8; color: #24292e; border: 1px solid #d1d5da;
            border-radius: 6px; cursor: pointer; opacity: 0; transition: opacity 0.2s;
        }}
        pre:hover .copy-btn {{ opacity: 1; }}
        @media (prefers-color-scheme: dark) {{ .copy-btn {{ background-color: #21262d; color: #c9d1d9; border-color: #30363d; }} }}
    </style>
</head>
<body>
    {toc_html}
    <main>{final_html_content}</main>
    <script>
        document.addEventListener("DOMContentLoaded", function() {{
            if (typeof mermaid !== 'undefined') mermaid.initialize({{ startOnLoad: true }});
            document.querySelectorAll('pre > code').forEach(function(codeBlock) {{
                var pre = codeBlock.parentElement;
                if (!pre) return;
                var button = document.createElement('button');
                button.className = 'copy-btn'; button.textContent = 'Copy';
                button.setAttribute('aria-label', 'Copy code to clipboard');
                button.addEventListener('click', function() {{
                    navigator.clipboard.writeText(codeBlock.innerText).then(function() {{
                        button.textContent = 'Copied!';
                        setTimeout(function() {{ button.textContent = 'Copy'; }}, 2000);
                    }});
                }});
                pre.appendChild(button);
            }});
        }});
    </script>
</body>
</html>"""
    return full_html_doc

async def display_lec_all_path(message: Message, repo_path: str, path: str, is_edit: bool = False):
    """Helper to fetch and display contents of a path in the lec_all repo."""
    status_msg = None
    if is_edit:
        # The callback is already answered, so we just edit the text.
        pass
    else:
        status_msg = await message.answer(f"–ó–∞–≥—Ä—É–∂–∞—é —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ `/{path or '–∫–æ—Ä–Ω—è'}` –∏–∑ `{repo_path}`...", parse_mode='markdown')

    contents = await github_service.get_github_repo_contents(repo_path, path)

    if contents is None:
        error_text = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è. –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ —Å —Ç–æ–∫–µ–Ω–æ–º GitHub –∏–ª–∏ API."
        if status_msg:
            await status_msg.edit_text(error_text)
        elif is_edit:
            await message.edit_text(error_text, reply_markup=None)
        else:
            await message.answer(error_text)
        return

    builder = InlineKeyboardBuilder()

    # Add a "back" button if not in the root directory
    if path:
        # The full path for navigation now includes the repo
        parent_dir = path.rsplit('/', 1) if '/' in path else ""
        parent_path = f"{repo_path}/{parent_dir}" if parent_dir else repo_path
        path_hash = hashlib.sha1(parent_path.encode()).hexdigest()[:16]
        kb.code_path_cache[path_hash] = parent_path
        builder.row(InlineKeyboardButton(text="‚¨ÖÔ∏è .. (–ù–∞–∑–∞–¥)", callback_data=f"abs_nav_hash:{path_hash}"))

    if not contents:
        # The directory is empty, but we still want to show the back button if applicable.
        pass
    elif isinstance(contents, list):
        for item in contents:
            if item['type'] == 'dir':
                full_item_path = f"{repo_path}/{item['path']}"
                path_hash = hashlib.sha1(full_item_path.encode()).hexdigest()[:16]
                kb.code_path_cache[path_hash] = full_item_path
                builder.row(InlineKeyboardButton(
                    text=f"üìÅ {item['name']}",
                    callback_data=f"abs_nav_hash:{path_hash}"
                ))
            elif item['type'] == 'file':
                full_item_path = f"{repo_path}/{item['path']}"
                path_hash = hashlib.sha1(full_item_path.encode()).hexdigest()[:16]
                kb.code_path_cache[path_hash] = full_item_path
                builder.row(InlineKeyboardButton(
                    text=f"üìÑ {item['name']}",
                    callback_data=f"abs_show_hash:{path_hash}"
                ))
    
    message_text = f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ: `/{path}` –≤ `{repo_path}`" if path else f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ `{repo_path}`"
    
    if not contents and not path: # Root is empty
        message_text = "–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø—É—Å—Ç."
    elif not contents and path: # Sub-directory is empty
        message_text = f"–ü–∞–ø–∫–∞ `/{path}` –ø—É—Å—Ç–∞."

    reply_markup = builder.as_markup() if builder.buttons else None

    if is_edit:
        try:
            await message.edit_text(message_text, reply_markup=reply_markup, parse_mode='markdown')
        except TelegramBadRequest as e:
            if "message is not modified" not in e.message:
                raise
    elif status_msg:
        await status_msg.edit_text(message_text, reply_markup=reply_markup, parse_mode='markdown')
    else:
        await message.answer(message_text, reply_markup=reply_markup, parse_mode='markdown')

async def show_code_by_path(message: Message, user_id: int, code_path: str, header: str):
    """Helper function to send code to the user based on its path."""
    try:
        submodule, topic, code_name = code_path.split('.')
        
        module = matplobblib._importlib.import_module(f'matplobblib.{submodule}')

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ docstring, –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        settings = await database.get_user_settings(user_id)
        dict_name = 'themes_list_dicts_full' if settings['show_docstring'] else 'themes_list_dicts_full_nd'
        code_dictionary = getattr(module, dict_name)

        repl = code_dictionary[topic][code_name]

        await message.answer(f'{header}: \n{code_path.replace(".", " -> ")}')
        
        if len(repl) > 4096:
            await message.answer('–°–æ–æ–±—â–µ–Ω–∏–µ –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∞—Å—Ç—è—Ö')
            for x in range(0, len(repl), 4096):
                await message.answer(f'''```python\n{repl[x:x+4096]}\n```''', parse_mode='markdown')
        else:
            await message.answer(f'''```python\n{repl}\n```''', parse_mode='markdown')
        
        await message.answer("–ß—Ç–æ –¥–µ–ª–∞–µ–º –¥–∞–ª—å—à–µ?", reply_markup=kb.get_code_action_keyboard(code_path))
        await message.answer("–ò–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –∫–æ–º–∞–Ω–¥—É.", reply_markup=kb.get_main_reply_keyboard(user_id))

    except (ValueError, KeyError, AttributeError, ImportError) as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∫–∞–∑–µ –∫–æ–¥–∞ (path: {code_path}): {e}")
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–ª–∏ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å —ç—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞. –í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω –±—ã–ª —É–¥–∞–ª–µ–Ω –∏–ª–∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω.")